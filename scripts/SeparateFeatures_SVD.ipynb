{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluating Singing Voice Detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../vocaldetection/')\n",
    "import sklearn\n",
    "import utils\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import arff, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know that the best parameters for training SVM and RF on this dataset are C=0.1 for SVM and nE=100 for RF. [WHY??]\n",
    "\n",
    "Then, I can just train the models with these parameters and see how the results on confusion changes.\n",
    "\n",
    "For each set of descriptors, I can do a cross validation evaluation and see the accuracy for each classifier.\n",
    "\n",
    "Then, I select the greater accuracy to be my reference of ceiling confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['MFCC','VV','FL','SC','SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['absent','present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for features calculated with Lehner Code\n",
    "all_feat_path = '/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/'\n",
    "f = all_feat_path+'ICASSP2014RNN/'\n",
    "\n",
    "mfcc_path = all_feat_path+'MFCC_29_30_0_0.5_0dt/40_20_40/'\n",
    "# Read features and labels\n",
    "FEAT_PATH = os.environ[\"FEAT_PATH\"]\n",
    "AUDIO_PATH = os.environ[\"AUDIO_PATH\"]\n",
    "PIECES = os.environ[\"PIECES_JSON\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Vocal Variance Separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vocal variance parameters \n",
    "# FRAMESIZE = 2205\n",
    "# HOPSIZE = 441\n",
    "# SR = 22050\n",
    "# # Function taken from https://github.com/kyungyunlee/ismir2018-revisiting-svd/blob/master/lehner_randomforest/vocal_var.py\n",
    "# def vocal_var(audiofile):\n",
    "#     ''' Compute vocal variance\n",
    "#     '''\n",
    "#     mfcc = librosa.feature.mfcc(audiofile, sr=SR, n_mfcc=30, n_fft=FRAMESIZE, hop_length=HOPSIZE, n_mels=128)\n",
    "#     mfcc = mfcc.swapaxes(0, 1)\n",
    "#     vv = np.empty([len(mfcc), 5])\n",
    "#     for i in range(len(mfcc)):\n",
    "#         for j in range(5):\n",
    "#             vv[i][j] = np.var(mfcc[max(0, i - 5): min(len(mfcc), i + 6), j + 1])\n",
    "#     return vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_files = []\n",
    "\n",
    "with open(PIECES) as json_file:  \n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    for music in data.keys():\n",
    "        music_files.append(music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read MFCC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/AClassicEducation_NightOwl_MIX.arff\n",
      "8572\n",
      "8572\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/AimeeNorwich_Child_MIX.arff\n",
      "18035\n",
      "18035\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/AlexanderRoss_GoodbyeBolero_MIX.arff\n",
      "38975\n",
      "38975\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/AlexanderRoss_VelvetCurtain_MIX.arff\n",
      "64699\n",
      "64699\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Auctioneer_OurFutureFaces_MIX.arff\n",
      "75093\n",
      "75093\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/AvaLuna_Waterduct_MIX.arff\n",
      "88058\n",
      "88058\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/BigTroubles_Phantom_MIX.arff\n",
      "95404\n",
      "95404\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/BrandonWebster_DontHearAThing_MIX.arff\n",
      "103986\n",
      "103986\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/BrandonWebster_YesSirICanFly_MIX.arff\n",
      "108968\n",
      "108968\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/CelestialShore_DieForUs_MIX.arff\n",
      "122901\n",
      "122901\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/ClaraBerryAndWooldog_AirTraffic_MIX.arff\n",
      "131573\n",
      "131573\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/ClaraBerryAndWooldog_Boys_MIX.arff\n",
      "139246\n",
      "139246\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/ClaraBerryAndWooldog_Stella_MIX.arff\n",
      "149033\n",
      "149033\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/ClaraBerryAndWooldog_TheBadGuys_MIX.arff\n",
      "161767\n",
      "161767\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/ClaraBerryAndWooldog_WaltzForMyVictims_MIX.arff\n",
      "170538\n",
      "170538\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Creepoid_OldTree_MIX.arff\n",
      "185648\n",
      "185648\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Debussy_LenfantProdigue_MIX.arff\n",
      "196824\n",
      "196824\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/DreamersOfTheGhetto_HeavyLove_MIX.arff\n",
      "211573\n",
      "211573\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/FacesOnFilm_WaitingForGa_MIX.arff\n",
      "224454\n",
      "224454\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/FamilyBand_Again_MIX.arff\n",
      "234518\n",
      "234518\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Handel_TornamiAVagheggiar_MIX.arff\n",
      "245668\n",
      "245668\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/HeladoNegro_MitadDelMundo_MIX.arff\n",
      "254760\n",
      "254760\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/HezekiahJones_BorrowedHeart_MIX.arff\n",
      "266838\n",
      "266838\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/HopAlong_SisterCities_MIX.arff\n",
      "281009\n",
      "281009\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/InvisibleFamiliars_DisturbingWildlife_MIX.arff\n",
      "291943\n",
      "291943\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/LizNelson_Coldwar_MIX.arff\n",
      "300442\n",
      "300442\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/LizNelson_ImComingHome_MIX.arff\n",
      "309426\n",
      "309426\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/LizNelson_Rainfall_MIX.arff\n",
      "323671\n",
      "323671\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MatthewEntwistle_DontYouEver_MIX.arff\n",
      "329371\n",
      "329371\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MatthewEntwistle_Lontano_MIX.arff\n",
      "344271\n",
      "344271\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Meaxic_TakeAStep_MIX.arff\n",
      "358406\n",
      "358406\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Meaxic_YouListen_MIX.arff\n",
      "379041\n",
      "379041\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Mozart_BesterJungling_MIX.arff\n",
      "387747\n",
      "387747\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Mozart_DiesBildnis_MIX.arff\n",
      "399203\n",
      "399203\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_80sRock_MIX.arff\n",
      "401048\n",
      "401048\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Beatles_MIX.arff\n",
      "402866\n",
      "402866\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Britpop_MIX.arff\n",
      "404705\n",
      "404705\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Country1_MIX.arff\n",
      "406442\n",
      "406442\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Country2_MIX.arff\n",
      "407314\n",
      "407314\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Disco_MIX.arff\n",
      "413552\n",
      "413552\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Gospel_MIX.arff\n",
      "417338\n",
      "417338\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Grunge_MIX.arff\n",
      "419430\n",
      "419430\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Hendrix_MIX.arff\n",
      "420422\n",
      "420422\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Punk_MIX.arff\n",
      "421860\n",
      "421860\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Reggae_MIX.arff\n",
      "422733\n",
      "422733\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Rock_MIX.arff\n",
      "423387\n",
      "423387\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/MusicDelta_Rockabilly_MIX.arff\n",
      "424684\n",
      "424684\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/NightPanther_Fire_MIX.arff\n",
      "435333\n",
      "435333\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/PortStWillow_StayEven_MIX.arff\n",
      "451183\n",
      "451183\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/PurlingHiss_Lolita_MIX.arff\n",
      "463994\n",
      "463994\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Schubert_Erstarrung_MIX.arff\n",
      "472688\n",
      "472688\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Schumann_Mignon_MIX.arff\n",
      "485829\n",
      "485829\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/SecretMountains_HighHorse_MIX.arff\n",
      "503604\n",
      "503604\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Snowmine_Curfews_MIX.arff\n",
      "517363\n",
      "517363\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/StevenClark_Bounty_MIX.arff\n",
      "531836\n",
      "531836\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/StrandOfOaks_Spacestation_MIX.arff\n",
      "544029\n",
      "544029\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/SweetLights_YouLetMeDown_MIX.arff\n",
      "563628\n",
      "563628\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/TheDistricts_Vermont_MIX.arff\n",
      "575035\n",
      "575035\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/TheScarletBrand_LesFleursDuMal_MIX.arff\n",
      "590216\n",
      "590216\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/TheSoSoGlos_Emergency_MIX.arff\n",
      "598566\n",
      "598566\n",
      "/media/shayenne/CompMusHD/DATASETS/MedleyDB/AllMusics/ICASSP2014/MFCC_29_30_0_0.5_0dt/40_20_40/Wolf_DieBekherte_MIX.arff\n",
      "608007\n",
      "608007\n"
     ]
    }
   ],
   "source": [
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "for tf in music_files:\n",
    "    try:\n",
    "        dataset = arff.load(open(mfcc_path+tf+'_MIX.arff', 'r'))\n",
    "        data = np.array(dataset['data'])\n",
    "        print (mfcc_path+tf+'_MIX.arff')\n",
    "    except FileNotFoundError:\n",
    "        print ('File not found: ',mfcc_path+tf+'_MIX.arff')\n",
    "        continue\n",
    "\n",
    "    # Calculate VV because it is not included on Lehner feature pack\n",
    "    #audiofile, _ = librosa.load(AUDIO_PATH+tf+'/'+tf+'_MIX.wav', sr=SR)\n",
    "    #vv=lbl = np.load(FEAT_PATH+tf+\"_vv_lee.npy\")\n",
    "    #print (vv.shape)\n",
    "    lbl = np.load(FEAT_PATH+tf+\"_labels_20ms.npy\")\n",
    "    \n",
    "    feature_vector = []\n",
    "    for idx in range(len(lbl)):\n",
    "        #feature_vector.append(np.concatenate((data[idx], vv[idx]), axis=0))\n",
    "        feature_vector.append(data[idx])\n",
    "        \n",
    "    # Store the feature vector and corresponding label in integer format\n",
    "    for idx in range(len(feature_vector)):\n",
    "        train_features.append(feature_vector[idx])\n",
    "        train_labels.append(lbl[idx])\n",
    "        \n",
    "    print (len(train_features))\n",
    "    print (len(train_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_features)\n",
    "y = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6880463547294686\n"
     ]
    }
   ],
   "source": [
    "# Percentage of singing voice frames on dataset\n",
    "print (sum(y)/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold # import KFold\n",
    "seed = 7\n",
    "kf = StratifiedKFold(n_splits=10, random_state=seed) # Define the split - into 2 folds \n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 38589  38590  38591 ... 608004 608005 608006] TEST: [    0     1     2 ... 71112 71113 71114]\n",
      "TRAIN: [     0      1      2 ... 608004 608005 608006] TEST: [ 38589  38590  38591 ... 137641 137642 137643]\n",
      "TRAIN: [     0      1      2 ... 608004 608005 608006] TEST: [ 87993  87994  87995 ... 202195 202196 202197]\n",
      "TRAIN: [     0      1      2 ... 608004 608005 608006] TEST: [148568 148569 148570 ... 253047 253048 253049]\n",
      "TRAIN: [     0      1      2 ... 608004 608005 608006] TEST: [198618 198619 198620 ... 307312 307313 307314]\n",
      "TRAIN: [     0      1      2 ... 608004 608005 608006] TEST: [286024 286025 286026 ... 380753 380754 380755]\n",
      "TRAIN: [     0      1      2 ... 608004 608005 608006] TEST: [345997 345998 345999 ... 429463 429464 429465]\n",
      "TRAIN: [     0      1      2 ... 608004 608005 608006] TEST: [405464 405465 405466 ... 491063 491064 491065]\n",
      "TRAIN: [     0      1      2 ... 608004 608005 608006] TEST: [473225 473226 473227 ... 551288 551289 551290]\n",
      "TRAIN: [     0      1      2 ... 551288 551289 551290] TEST: [536553 536554 536555 ... 608004 608005 608006]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X,y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "\n",
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(cm):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(cm, interpolation='nearest', cmap='gray')\n",
    "    for i, line in enumerate(cm):\n",
    "        for j, l in enumerate(line):\n",
    "            ax.text(j, i, l, size=20, color='green')\n",
    "    ax.set_xticks(range(len(cm)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticks(range(len(cm)))\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608007, 60)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier without scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to train a model with the training features we've extracted\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "\n",
    "def rf_param_selection(X, y, nfolds):\n",
    "    n_estimators = [int(x) for x in np.linspace(10, 200, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]# Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    print (random_grid)\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestClassifier()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                                   n_iter = 100, cv = nfolds, verbose=2, random_state=42, \n",
    "                                   n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X, y)\n",
    "    print (rf_random.best_params_)\n",
    "    return rf_random.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 10\n",
    "best_rf = rf_param_selection(X, y, nfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=157, min_samples_split=10, min_samples_leaf=1, \n",
    "                            max_features='sqrt', max_depth=20, bootstrap=True, random_state=42)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets predict the labels of the test data!\n",
    "predictions = rf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biased Guess Accuracy\n",
    "ones = np.ones(len(predictions))\n",
    "accuracy = sklearn.metrics.accuracy_score(y, ones)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF Accuracy\n",
    "accuracy = sklearn.metrics.accuracy_score(y, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "metrics = precision_recall_fscore_support(y, predictions)\n",
    "print('Negatives : ', metrics[3][0],'- Positives',metrics[3][1])\n",
    "print('Precision :', round(metrics[0][1],3))\n",
    "print('Recall    :', round(metrics[1][1],3))\n",
    "print('F-score   :', round(metrics[2][1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compute the show the confusion matrix:\n",
    "cm = sklearn.metrics.confusion_matrix(y, predictions)\n",
    "plot_cm(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing in one piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_name = 'LizNelson_Rainfall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vggish = pd.read_csv(VGGish_PATH+piece_name+\"_VGGish_PCA.csv\",index_col=None, header=None)\n",
    "#vggish = vggish.values\n",
    "mfcc_piece = mfcc_path+piece_name+'_MIX.arff'\n",
    "dataset = arff.load(open(mfcc_piece, 'r'))\n",
    "data = np.array(dataset['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_features = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = rf.predict(piece_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_test = np.load(FEAT_PATH+piece_name+\"_labels_20ms.npy\")\n",
    "print (piece_test.shape, piece_features.shape)\n",
    "#piece_test = piece_test[:piece_features.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF VGGish Accuracy\n",
    "accuracy = sklearn.metrics.accuracy_score(piece_test, pred_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compute the show the confusion matrix:\n",
    "cm = sklearn.metrics.confusion_matrix(piece_test, pred_labels)\n",
    "plot_cm(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,3))\n",
    "plt.plot(piece_test+2)\n",
    "plt.plot(pred_labels+1)\n",
    "plt.plot(scipy.signal.medfilt(pred_labels,kernel_size=5))\n",
    "plt.plot(proba-1)\n",
    "plt.plot(scipy.signal.medfilt(proba,kernel_size=5)-2)\n",
    "thresh = np.zeros(len(proba))\n",
    "thresh[scipy.signal.medfilt(proba,kernel_size=3) >= 0.5] = 1\n",
    "plt.plot(thresh-3)\n",
    "plt.legend(['Original Label', 'Predicted Label', 'Filter Prediction', \n",
    "            'Probabilities', 'Filter Probabilities', 'Threshold Prob'], bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
